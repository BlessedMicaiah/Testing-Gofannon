{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lHgQpyt47ZlX",
        "outputId": "401689a2-45fb-4519-f8ef-b22f9f1f661f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[33mDEPRECATION: git+https://github.com/rawkintrevo/gofannon.git@19#egg=gofannon[headless_browser] contains an egg fragment with a non-PEP 508 name pip 25.0 will enforce this behaviour change. A possible replacement is to use the req @ url syntax, and remove the egg fragment. Discussion can be found at https://github.com/pypa/pip/issues/11617\u001b[0m\u001b[33m\n",
            "\u001b[0m  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.5/9.5 MB\u001b[0m \u001b[31m40.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m486.3/486.3 kB\u001b[0m \u001b[31m22.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for gofannon (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "!pip install \"git+https://github.com/rawkintrevo/gofannon.git@19#egg=gofannon[headless_browser]\" --quiet"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Show that a site can't be loaded with `requests.get`\n",
        "\n",
        "The site https://app-template-37928.web.app is a failed attempt at teaching myself material in I want to say the late 2010s. It's a really small site, and if java script isn't enabled it will fail. Click and go to the site, you'll see it is very little besides 'home works!'. We try to load it with requests and don't even get that much."
      ],
      "metadata": {
        "id": "D-B5Ecv5F8Cu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from requests import get\n",
        "\n",
        "r = get('https://app-template-37928.web.app/')\n",
        "\n",
        "print('home works' in r.text)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8FcWFDJK-Sp9",
        "outputId": "a4496589-8268-41ef-ac2a-0bfe85f09e79"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "False\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Using `headless_browser_get` we do see it.\n",
        "\n",
        "In the next couple of blocks we'll load the same site with a headless browser, so the java script will render, and then we'll have the LLM describe the page to us."
      ],
      "metadata": {
        "id": "HHOBsxLBGZQz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from openai import OpenAI\n",
        "from google.colab import userdata\n",
        "import json\n",
        "# Create an OpenAI client with your deepinfra token and endpoint\n",
        "openai = OpenAI(\n",
        "    api_key=userdata.get('deepinfra'),\n",
        "    base_url=\"https://api.deepinfra.com/v1/openai\",\n",
        ")\n",
        "\n",
        "from gofannon.headless_browser.headless_browser_get import HeadlessBrowserGet\n",
        "\n",
        "\n",
        "\n",
        "tool_list =  [F() for F in [HeadlessBrowserGet]]\n",
        "tool_map = {f.name: f.fn for f in tool_list}\n",
        "tool_desc_list = [f.definition for f in tool_list]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4lQM_0TC78if",
        "outputId": "74e453d3-24aa-46e5-87e1-e3d6e410c698"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/gofannon/headless_browser/base.py:3: LangChainDeprecationWarning: As of langchain-core 0.3.0, LangChain uses pydantic v2 internally. The langchain.pydantic_v1 module was a compatibility shim for pydantic v1, and should no longer be used. Please update the code to import from Pydantic directly.\n",
            "\n",
            "For example, replace imports like: `from langchain.pydantic_v1 import BaseModel`\n",
            "with: `from pydantic import BaseModel`\n",
            "or the v1 compatibility namespace if you are working in a code base that has not been fully upgraded to pydantic 2 yet. \tfrom pydantic.v1 import BaseModel\n",
            "\n",
            "  from ..base import BaseTool\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# here is the user request\n",
        "messages = [\n",
        "    {\n",
        "        \"role\": \"user\",\n",
        "        \"content\": \"Describe the text you find on the page https://app-template-37928.web.app\"\n",
        "    }\n",
        "]\n",
        "\n",
        "# let's send the request and print the response\n",
        "response = openai.chat.completions.create(\n",
        "    model=\"meta-llama/Llama-3.3-70B-Instruct\",\n",
        "    messages=messages,\n",
        "    tools=tool_desc_list,\n",
        "    tool_choice=\"auto\",\n",
        ")\n",
        "tool_calls = response.choices[0].message.tool_calls\n",
        "for tool_call in tool_calls:\n",
        "    print(tool_call.model_dump())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HlqQom0a9O_d",
        "outputId": "e0ad1be5-f9a2-4b82-a87f-1d1fed375273"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'id': 'call_yZXQ93eKcBG3VcqgEn1LVizw', 'function': {'arguments': '{\"url\": \"https://app-template-37928.web.app\"}', 'name': 'headless_browser_get'}, 'type': 'function'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "messages.append(response.choices[0].message)\n",
        "\n",
        "for tool_call in tool_calls:\n",
        "  function_name = tool_call.function.name\n",
        "  function_args = json.loads(tool_call.function.arguments)\n",
        "  function_response = tool_map[function_name](**function_args)\n",
        "\n",
        "  # extend conversation with function response\n",
        "  messages.append({\n",
        "      \"tool_call_id\": tool_call.id,\n",
        "      \"role\": \"tool\",\n",
        "      \"content\": function_response,\n",
        "  })\n",
        "\n",
        "\n",
        "# get a new response from the model where it can see the function responses\n",
        "second_response = openai.chat.completions.create(\n",
        "  model=\"meta-llama/Meta-Llama-3.1-70B-Instruct\",\n",
        "  messages=messages,\n",
        "  tools=tool_desc_list,\n",
        "  tool_choice=\"auto\",\n",
        ")\n",
        "\n",
        "print(second_response.choices[0].message.content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5b9e6gvT_7VF",
        "outputId": "31d9ac64-70f1-4a46-840c-9f5ad2399b03"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The text on the page https://app-template-37928.web.app is:\n",
            "\n",
            "\"home works!\"\n",
            "\n",
            "This is the content of the <h1> tag in the <app-home> component, which is rendered inside the <router-outlet> element in the main app component.\n",
            "\n",
            "There is also a navigation menu with several links, including \"update\", \"schedule\", \"face\", and \"login\". The \"login\" link is a router link that navigates to the \"/login\" route.\n",
            "\n",
            "Additionally, there is a toolbar with a toggle button for the side navigation menu, and a title that says \"[AppTitle Here]\".\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## It Works\n",
        "\n",
        "As we can see the headless_browser_get did a bang up job of fetching content that requires client side js rendering."
      ],
      "metadata": {
        "id": "WrafDljWGzrh"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "tt_UYYQpAXyP"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}